# DataLab â€“ Feedback 1 (ProgramaciÃ³n Concurrente)

Este proyecto es la resoluciÃ³n del **Feedback 1 de ProgramaciÃ³n Concurrente**.  
La idea principal es construir un **servicio REST en Spring Boot** capaz de recibir trabajos (*Jobs*) de anÃ¡lisis de datasets (CSV), dividirlos en tareas (*Tasks*) y ejecutarlas **en paralelo**, aplicando concurrencia, transacciones, AOP y buenas prÃ¡cticas de diseÃ±o.

No es un â€œhola mundoâ€: aquÃ­ hay **paralelismo real**, control de estados, reintentos, auditorÃ­a y mÃ©tricas.

---

## ğŸ§  Idea general

El sistema funciona asÃ­:

1. Se crea un **Job** con un dataset (CSV) y un nÃºmero de *shards*.
2. El Job se divide en varias **Tasks**.
3. Cada Task analiza una parte distinta del CSV.
4. Las Tasks se ejecutan **en paralelo** usando un pool de hilos.
5. Cada Task genera un **Result** con estadÃ­sticas reales (sum, avg, min, max).
6. Al finalizar, el Job pasa a `COMPLETED`, `PARTIAL_SUCCESS`, `FAILED` o `CANCELLED`.

Todo el flujo estÃ¡ instrumentado con **AOP**, **transacciones** y **auditorÃ­a**.

---

## ğŸ—ï¸ Arquitectura y paquetes

La estructura del proyecto sigue una separaciÃ³n clara por capas:

juanma.datalab

â”œâ”€ aspects/ â†’ AOP (performance, retry)

â”œâ”€ config/ â†’ executor, async, datasource

â”œâ”€ controller/ â†’ API REST

â”œâ”€ domain/ â†’ Job, Task, Result

â”œâ”€ dto/ â†’ requests y responses

â”œâ”€ repository/ â†’ Spring Data JPA

â””â”€ service/ â†’ lÃ³gica de negocio y concurrencia



La lÃ³gica **nunca estÃ¡ en los controladores**: todo pasa por servicios.

---

## âš™ï¸ TecnologÃ­as usadas

- **Spring Boot 3**
- Spring Web
- Spring Data JPA
- Spring AOP
- Spring Validation
- H2 (perfil `dev`)
- PostgreSQL + HikariCP (perfil `prod`)
- Lombok
- Java 17

---

## ğŸ”„ Concurrencia

La concurrencia se implementa usando:

- `ThreadPoolTaskExecutor` configurable
- `@EnableAsync`
- `@Async`
- `CompletableFuture` para fan-out / fan-in

Cada Task se ejecuta en paralelo y el Job espera a que todas terminen para decidir el estado final.

---

## ğŸ§© Estrategias de anÃ¡lisis (IoC / DI)

El anÃ¡lisis del CSV no estÃ¡ â€œhardcodeadoâ€. Se usa una interfaz:

- `AnalyzerStrategy`

Implementaciones:
- `SimpleAnalyzer` â†’ estrategia por defecto (`@Primary`)
- `AdvancedAnalyzer` â†’ solo activa en perfil `prod`

Esto permite cambiar el comportamiento **sin tocar el resto del sistema**, demostrando uso real de IoC y DI.

---

## ğŸ” Reintentos automÃ¡ticos (AOP)

Las Tasks pueden fallar por errores transitorios.  
Para eso se ha implementado:

- AnotaciÃ³n personalizada `@RetryableTransient`
- Aspecto que reintenta la ejecuciÃ³n con backoff
- ExcepciÃ³n `TransientDataException`

Los reintentos se aplican **solo donde tiene sentido**.

---

## â±ï¸ MÃ©tricas y trazabilidad (AOP + MDC)

Existe un `PerformanceAspect` que:

- Mide el tiempo de ejecuciÃ³n de servicios y repositorios
- AÃ±ade un `traceId` a cada peticiÃ³n usando MDC
- Permite seguir un Job completo en logs fÃ¡cilmente

El traceId se genera al inicio de cada peticiÃ³n HTTP mediante un filtro servlet y se propaga a travÃ©s de MDC, permitiendo correlacionar logs incluso en ejecuciones asÃ­ncronas.


---

## ğŸ§¾ AuditorÃ­a con REQUIRES_NEW

Cuando una Task falla definitivamente:

- Se registra el fallo en un **servicio de auditorÃ­a**
- Usa `@Transactional(REQUIRES_NEW)`
- El fallo se audita **sin romper la transacciÃ³n principal**

Esto demuestra control avanzado de transacciones.

---

## ğŸ—„ï¸ Persistencia y perfiles

### Perfil `dev`
- Base de datos H2 en memoria
- `ddl-auto: update`
- Consola H2 habilitada

### Perfil `prod`
- PostgreSQL
- Pool de conexiones **HikariCP**
- ConfiguraciÃ³n realista de producciÃ³n

No es necesario levantar PostgreSQL para la entrega: el perfil estÃ¡ definido y documentado.

---

## ğŸŒ API REST disponible

### Crear Job (JSON)
POST /api/jobs

### Crear Job (CSV multipart)
POST /api/jobs

### Consultar estado del Job
GET /api/jobs/{id}

### Obtener resultados paginados
GET /api/jobs/{id}/results?page=0&size=10

### Cancelar Job
POST /api/jobs/{id}:cancel

### Health check
GET /health  
Endpoint tÃ©cnico para comprobar que el servicio estÃ¡ levantado.

---

## ğŸ§ª CÃ³mo probar el proyecto

### ğŸ“¦ Empaquetado como fat jar

El proyecto se empaqueta como un **fat jar ejecutable** usando Spring Boot:

mvn clean package  
java -jar target/datalab-0.0.1-SNAPSHOT.jar

De esta forma la aplicaciÃ³n puede ejecutarse sin necesidad de un servidor externo.


### â–¶ï¸ Arrancar el servidor

#### Windows (PowerShell)
```mvn spring-boot:run```

#### Linux / macOS
```mvn spring-boot:run```

El servidor arranca en http://localhost:8080.

### ğŸ§ª Prueba 1: Crear un Job (JSON)

#### Windows (PowerShell)
```
$body = @{
  sourceUrl = "classpath:customer_purchases_1000.csv"
  shards = 6
} | ConvertTo-Json

Invoke-RestMethod -Method Post `
  -Uri "http://localhost:8080/api/jobs" `
  -ContentType "application/json" `
  -Body $body
```
#### Linux / macOS
```
curl -X POST http://localhost:8080/api/jobs \
  -H "Content-Type: application/json" \
  -d '{"sourceUrl":"classpath:customer_purchases_1000.csv","shards":6}'
```
### ğŸ§ª Prueba 2: Ver estado del Job
```GET /api/jobs/{id} ```

Se puede observar el progreso (%) y el estado final.

### ğŸ§ª Prueba 3: Ver resultados paginados
```GET /api/jobs/{id}/results?page=0&size=5 ```

### ğŸ§ª Prueba 4: Cancelar un Job en ejecuciÃ³n
```POST /api/jobs/{id}:cancel ```
Las Tasks activas detectan el flag y se cancelan correctamente.

### ğŸ§ª Prueba 5: Ver reintentos y auditorÃ­a
- El sistema provoca fallos transitorios de forma controlada.
- Se observan reintentos en logs.
- Si una Task falla definitivamente, aparece un registro [AUDIT].
